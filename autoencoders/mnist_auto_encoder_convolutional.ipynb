{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, Dropout, LeakyReLU, Input, BatchNormalization, Softmax, Reshape, Conv2DTranspose, Activation\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_real_data_items = train_images.shape[0]\n",
    "num_test_real_data_items = test_images.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation_funcion = Activation(\"tanh\")\n",
    "# activation_funcion = Activation(\"sigmoid\")\n",
    "activation_funcion = LeakyReLU(alpha=0.2)\n",
    "use_normalisation = True\n",
    "use_dropout = True\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_kernal_nums = [20,]\n",
    "encoder_kernal_sizes = [3]\n",
    "assert len(encoder_kernal_sizes) == len(encoder_kernal_nums)\n",
    "\n",
    "encoder_dense_layer_neurons = [100, 100]\n",
    "latent_space_size = 100\n",
    "assert latent_space_size == encoder_dense_layer_neurons[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_encoder = Sequential()\n",
    "\n",
    "model_encoder.add(Input((28, 28, 1)))\n",
    "\n",
    "for kernal_size, kernal_num in zip(encoder_kernal_sizes, encoder_kernal_nums):\n",
    "    model_encoder.add(\n",
    "        Conv2D(\n",
    "            kernal_num,\n",
    "            kernel_size=(kernal_size, kernal_size), \n",
    "            kernel_initializer=RandomNormal(stddev=0.02)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if use_dropout:\n",
    "        model_encoder.add(Dropout(dropout))\n",
    "\n",
    "    if use_normalisation:\n",
    "        model_encoder.add(BatchNormalization())\n",
    "\n",
    "    model_encoder.add(activation_funcion)\n",
    "\n",
    "model_encoder.add(\n",
    "    Flatten()\n",
    ")\n",
    "\n",
    "for num_neurons in encoder_dense_layer_neurons:\n",
    "    model_encoder.add(\n",
    "        Dense(num_neurons)\n",
    "    )\n",
    "\n",
    "    model_encoder.add(activation_funcion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1 (Conv2D)           (None, 26, 26, 20)        200       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 26, 26, 20)        0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 26, 26, 20)        80        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   multiple                  0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 13520)             0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 100)               1352100   \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1362480 (5.20 MB)\n",
      "Trainable params: 1362440 (5.20 MB)\n",
      "Non-trainable params: 40 (160.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder model structure based on emulating encoder structure in reverse\n",
    "\n",
    "dencoder_dense_layer_neurons = [10_000, 135_200]\n",
    "dencoder_kernal_nums = [20,]\n",
    "dencoder_kernal_sizes = [3]\n",
    "convolutional_layer_shape = (26, 26, 4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"reshape\" (type Reshape).\n\ntotal size of new array must be unchanged, input_shape = [10000], output_shape = [26, 26, 4, 1]\n\nCall arguments received by layer \"reshape\" (type Reshape):\n  • inputs=tf.Tensor(shape=(None, 10000), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 12\u001b[0m\n\u001b[0;32m      7\u001b[0m     model_encoder\u001b[38;5;241m.\u001b[39madd(\n\u001b[0;32m      8\u001b[0m         Dense(num_neurons)\n\u001b[0;32m      9\u001b[0m     )\n\u001b[0;32m     10\u001b[0m     model_encoder\u001b[38;5;241m.\u001b[39madd(activation_funcion)\n\u001b[1;32m---> 12\u001b[0m \u001b[43mmodel_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mReshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvolutional_layer_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m kernal_size, kernal_num \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mreversed\u001b[39m(dencoder_kernal_sizes), \u001b[38;5;28mreversed\u001b[39m(dencoder_kernal_nums)):\n\u001b[0;32m     17\u001b[0m     model_encoder\u001b[38;5;241m.\u001b[39madd(\n\u001b[0;32m     18\u001b[0m         Conv2DTranspose(\n\u001b[0;32m     19\u001b[0m             kernal_num,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m         )\n\u001b[0;32m     23\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Henry\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\trackable\\base.py:204\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 204\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Henry\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Henry\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\reshape.py:118\u001b[0m, in \u001b[0;36mReshape._fix_unknown_dimension\u001b[1;34m(self, input_shape, output_shape)\u001b[0m\n\u001b[0;32m    116\u001b[0m     output_shape[unknown] \u001b[38;5;241m=\u001b[39m original \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m known\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m original \u001b[38;5;241m!=\u001b[39m known:\n\u001b[1;32m--> 118\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output_shape\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"reshape\" (type Reshape).\n\ntotal size of new array must be unchanged, input_shape = [10000], output_shape = [26, 26, 4, 1]\n\nCall arguments received by layer \"reshape\" (type Reshape):\n  • inputs=tf.Tensor(shape=(None, 10000), dtype=float32)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model_encoder = Sequential()\n",
    "\n",
    "\n",
    "model_encoder.add(Input(latent_space_size))\n",
    "\n",
    "for num_neurons in reversed(dencoder_dense_layer_neurons):\n",
    "    model_encoder.add(\n",
    "        Dense(num_neurons)\n",
    "    )\n",
    "    model_encoder.add(activation_funcion)\n",
    "\n",
    "model_encoder.add(\n",
    "    Reshape(convolutional_layer_shape)\n",
    ")\n",
    "\n",
    "for kernal_size, kernal_num in zip(reversed(dencoder_kernal_sizes), reversed(dencoder_kernal_nums)):\n",
    "    model_encoder.add(\n",
    "        Conv2DTranspose(\n",
    "            kernal_num,\n",
    "            kernel_size=(kernal_size, kernal_size), \n",
    "            kernel_initializer=RandomNormal(stddev=0.02)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if use_dropout:\n",
    "        model_encoder.add(Dropout(dropout))\n",
    "\n",
    "    if use_normalisation:\n",
    "        model_encoder.add(BatchNormalization())\n",
    "\n",
    "    model_encoder.add(activation_funcion)\n",
    "\n",
    "\n",
    "model_encoder.add(Reshape((28, 28, 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
